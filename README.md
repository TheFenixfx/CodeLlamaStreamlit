# CodeLlama Documents with UI
Load Documents into a LLM using a VectorStore and get Context about it. The more paramaters and better embedings used, better results. 

Python Code with Streamlit
Langchain and local model compatibility through LlamaCPP ( Langchain implementation )

THe only thing that makes this a Codellama version is the prompt and model used. Prompt + Finetune + change the model, for your use case.


Require : 
Nvidia GPU +8GB
Chromadb / Langchain / Streamlit
Anaconda is recommended for this. 
